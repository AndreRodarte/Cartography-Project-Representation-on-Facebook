---
author: "André K. Rodarte"
date: "2023-06-12"
output: html_document
---

# **Political Representation and Propaganda on Facebook: 2022 Brazilian Elections**


```{r setup, echo=T, results='hide', message=FALSE, warning=FALSE}
options(scipen = 999)  #R uses scientific notations as a default. 
#citation("DHARMa")
library(tidyverse)
library(readr)
library(stringdist)
library(datasets)
library(janitor)
library(lubridate)
library(tidytext)
library(stringr)
library(tokenizers)
library(wordcloud)
library(textdata)
library(geobr)
library(ggplot2)
library(sf)
library(dplyr)
library(ggmap)
library(broom)
library(RColorBrewer)
library(viridis)
library(igraph) 
library(ggraph) 
library(widyr)
library(janeaustenr)
library("lexiconPT")
library(stringi)
library(purrr)

#Regression analysis
#install.packages("caret")
#install.packages("car")
#install.packages("leaps")
#install.packages("MASS")
#install.packages("partykit")
#install.packages("nnet")
#install.packages("EMT")
#install.packages("DHARMa")
library(caret)
library(car)
library(leaps)
library(MASS)
library(partykit)
library(nnet)
library(EMT)
library(DHARMa)

#DATA VISUALIZATION
#install.packages('maps')
#install.packages("tibble")
#install.packages("forcats")
#install.packages("plotly")
library(maps)
library(plotly)
library(tibble)
library(forcats)

#Facebook Ads
library(highcharter)
library(httr)
library(furrr)
library(remotes)
```

```{r, message=FALSE, warning=FALSE}
#DATASETS
CrowdTangle <- readr::read_csv('(CART) (COLLECTTED 4-1-2023) CrowdTangle Historical-Report- Parliamentary Candidates MG - 2022-01-01-UNTIL-2023-01-02.csv') %>% 
  select(page_name, page_likes, page_followers, timestamp, body, body_description, views_total, interactions, comments, views_post, shares, likes, likes_wow, likes_love, likes_angry, likes_sad)
  
# Excluding posts created after the election.
CrowdTangle$timestamp <- as.Date(CrowdTangle$timestamp, format = "%m/%d/%Y")
CrowdTangle$postID<-row.names(CrowdTangle)
cutoff_date <- as.Date("2022-10-02")

# Subset the data frame to exclude posts before the cutoff date
CrowdTangle <- CrowdTangle[CrowdTangle$timestamp <= cutoff_date, ]
#This sample procedure yielded a total of 73,159 Facebook posts. 

#Data on the municipalities of the state of Minas Gerais (MG)
MGMunicipalities <- readr::read_csv('ListMunicipalitiesIBGE.csv',
    col_types = cols(Population = col_number(), 
        Medium_Salary = col_number(), PIB_per_capita = col_number(), 
        GINI = col_number(), Area = col_number(), 
        Urban_Area = col_number(), Demographic_Density = col_number()))

#Data on the campaign expenses 
dfExpensesTotal <- readr::read_csv("dfCampaignExpenses.csv")%>% 
  select(SG_UF, DS_CARGO, NR_CANDIDATO, full_name, party, party_abbrev, NM_FORNECEDOR, DS_ORIGEM_DESPESA, DS_DESPESA, VR_DESPESA_CONTRATADA) %>% 
  filter(DS_CARGO == "Deputado Federal")

  #Expenses grouped by candidate 
  dfExpenses <- dfExpensesTotal %>%
    group_by(full_name) %>%
    summarise(Expenses = sum(VR_DESPESA_CONTRATADA))
  #Adding expenses with online content promotion
  dfExpenses_FB <- dfExpensesTotal %>% 
          filter(str_detect(DS_ORIGEM_DESPESA, "Despesa com Impulsionamento de Conteúdos", negate = F)) %>% 
          group_by(full_name) %>%
          summarise(ExpensesAds = sum(VR_DESPESA_CONTRATADA))
  dfExpenses <- left_join(dfExpenses, dfExpenses_FB, by="full_name")
```

## CrowdTangle

I combined the TSE data set with information about the candidates' communications on social media, specifically their account names, number of views and number of interactions.

```{r, message=FALSE, warning=FALSE}
#First, I create a new dataset combining all interactions these candidates received during the election
CrowdTangle_Engagement <- CrowdTangle %>%
  group_by(page_name) %>%
  summarize(N_Posts = n(),
            Total_Views = sum(views_total),
            Total_Interactions = sum(interactions),
            Total_Comments = sum(comments),
            Total_Post_Views = sum(views_post),
            Total_Shares = sum(shares),
            Total_Likes = sum(likes),
            Total_Angy = sum(likes_angry))

#The new dataset is: 
dfTSE <- read_delim("df_TSE.csv", delim = ";", 
    escape_double = FALSE, trim_ws = TRUE)
df_combined <- left_join(dfTSE, CrowdTangle_Engagement, by="page_name")


#Translating the gender variables
df_combined$gender <- str_replace_all(df_combined$gender,'Masculino','Masculine')
df_combined$gender <- str_replace_all(df_combined$gender,'Feminino','Feminine')
#Translating the race variable
df_combined$race <- case_when(
  df_combined$race == 'BRANCA' ~ 'White',
  df_combined$race %in% c('PRETA', 'PARDA', 'AMARELA', 'INDÍGENA') ~ 'Non-White',
  df_combined$race == 'SEM INFORMAÇÃO' ~ 'No information',
  TRUE ~ df_combined$race
)
#Translating the education variable
df_combined$education <- case_when(
  df_combined$education == 'Superior completo' ~ 'College Complete',
  df_combined$education %in% c('Superior incompleto', 'Ensino Médio completo', 'Ensino Médio incompleto',
                               'Ensino Fundamental completo', 'Ensino Fundamental incompleto', 'Lê e escreve') ~ 'College incomplete or less',
  TRUE ~ df_combined$education
)
#Translating (some) previous occupations
df_combined$occupation <- case_when(
  df_combined$occupation == 'Gari ou Lixeiro' ~ 'Cleaner',
  df_combined$occupation == 'Deputado' ~ 'Deputy',
  df_combined$occupation == 'Ator e Diretor de Espetáculos Públicos' ~ 'Actor or Director of Public Spectacles',
  df_combined$occupation == 'Vereador' ~ 'Member of City Council',
  df_combined$occupation == 'Veterinário' ~ 'Veterinarian',
  df_combined$occupation == 'Servidor Público Federal' ~ 'Public Servant',
  df_combined$occupation == 'Policial Civil' ~ 'Police (Civil)',
  df_combined$occupation == 'Jornalista e Redator' ~ 'Journalist',
  df_combined$occupation == 'Advogado' ~ 'Lawyer',
  df_combined$occupation == 'Psicólogo' ~ 'Psychologist',
  df_combined$occupation == 'Fotógrafo e Assemelhados' ~ 'Photographer (and similar professions)',
  df_combined$occupation == 'Pecuarista' ~ 'Rancher',
  df_combined$occupation == 'Outros' ~ 'Other',
  df_combined$occupation == 'Empresário' ~ 'Businessperson',
  df_combined$occupation == 'Comerciante' ~ 'Merchant',
  df_combined$occupation == 'Administrador' ~ 'Manager',
  df_combined$occupation == "Aposentado (Exceto Servidor Público)" ~ 'Retired (except former public servants)',
  df_combined$occupation == 'Agente Administrativo' ~ 'Administrative Agent',
  df_combined$occupation == 'Agente de Saúde e Sanitarista' ~ 'Health and Sanitation Agent',
  TRUE ~ df_combined$occupation
)

#Parsing spent and received funds
df_combined$received_funds <- parse_number(df_combined$received_funds)
df_combined$spent_funds <- parse_number(df_combined$spent_funds)

#Creating a metric for absolute engagement
df_combined$Absolute_Engagement = rowSums(df_combined[,c("Total_Post_Views", "Total_Interactions", "Total_Comments")]) 

#Creating a metric for relative engagement
df_combined$Relative_Engagement = rowSums(df_combined[,c("Total_Post_Views", "Total_Interactions", "Total_Comments")]) / df_combined$N_Posts

#Adding data about candidate's declared wealth and campaign expenses
Wealth <- read.csv("Wealth.csv") %>% 
  select(full_name, Bens_Declarados)

colnames(Wealth)[colnames(Wealth) == "Bens_Declarados"] <- "Declared_Wealth"

df <- left_join(df_combined, Wealth, by="full_name")
df <- left_join(df, dfExpenses, by="full_name")
```

**Descriptive analysis of the entire sample**

```{r}
df_total <- df %>% 
  mutate(interaction = interaction(gender, race, education, sep = " ")) %>% 
  group_by(interaction) %>%
  summarise(Composition = n(),
            Expenses = mean(Expenses, na.rm = TRUE),
            ExpensesAds = mean(ExpensesAds, na.rm = TRUE),
            Wealth = mean(Declared_Wealth, na.rm = TRUE), 
            RelativeEngagement = mean(Relative_Engagement, na.rm = TRUE))
```

```{r}
df_total_arranged <- df_total %>%
  filter(!is.na(ExpensesAds)) %>%
  filter(!is.na(Wealth)) %>%
  filter(!is.na(RelativeEngagement))
  

df_total_arranged %>% 
  ggplot(aes(x=Expenses, y = fct_reorder(interaction, Expenses))) +
  geom_boxplot(fill = "slateblue", alpha = 0.2, notch = TRUE, fatten = 5,
               notchwidth = 1) +
  xlab("Campaign Expenditure") +
  ylab("")
```

```{r}
df_total_arranged %>% 
  ggplot(aes(x = RelativeEngagement, y = fct_reorder(interaction, RelativeEngagement))) +
  geom_boxplot(fill = "slateblue", alpha = 0.2, notch = TRUE, fatten = 5,
               notchwidth = 1) +
  xlab("Relative Engagement on Facebook") +
  ylab("")
```

# [RQ1] Supply side

## What kind of candidate was not on Facebook during the last electoral cycle?

```{r}
df_nas <- df[is.na(df$page_name), ] #Separating the dataset
```

```{r}
nas_intersections <- df_nas %>%
  mutate(interaction = interaction(gender, race, education, sep = " ")) %>% 
  group_by(interaction) %>%
  summarise(Composition = n(),
            Expenses = mean(Expenses, na.rm = TRUE),
            Wealth = mean(Declared_Wealth, na.rm = TRUE)) %>% 
  arrange(desc(Wealth),by_group = TRUE)

nas_intersections
```

**Analysis:** there were 1018 candidates who ran for the Chamber of Federal Deputies in 2022, 659 of them did not have an active, public account on Facebook. By analyzing the intersection of gender, race, and education, we can verify that the most numerous kind of candidate that was absent from this platform were men of color with lower levels of education (n = 133).

Specifically, we have:

|               |                           |                                |
|---------------|---------------------------|--------------------------------|
| **Gender**    | 256 women                 | 403 men                        |
| **Race**      | 361 non-white             | 291 white                      |
| **Education** | 287 with college complete | 372 college incomplete or less |

: *Table 1: Absent from Facebook*


```{r}
interactions_occupation <- df_nas %>%
     group_by(occupation) %>%
     summarise(Composition = n(), 
               Expenses = mean(Expenses, na.rm = TRUE)) 

interactions_occupation %>% 
  arrange(desc(Composition),by_group = TRUE)
```


## **Is there a relationship between engagement on Facebook and candidates' profiles?**

```{r}
df_clean <- df %>% 
  filter(!is.na(N_Posts))

table(df_clean$education) #A similar code was used to verify the number of candidates of different gender and race. 
```

|               |                                |                      |
|---------------|--------------------------------|----------------------|
| **Gender**    | 86 women                       | 265 men              |
| **Race**      | 146 non-white                  | 205 white            |
| **Education** | 107 college incomplete or less | 244 college complete |

: *Table 1: Candidates with a Facebook account*

### Voters interacted the most with candidates of what gender?

```{r}
interactions_gender <- df_clean %>%
     group_by(gender) %>%
     summarise(n = n(), Engagement = sum(Absolute_Engagement), Mean = mean(Absolute_Engagement), sd = sd(Absolute_Engagement), Comments = sum(Total_Comments), Expenses = mean(Expenses, na.rm = T), ExpensesAds = mean(ExpensesAds, na.rm = TRUE)) 

interactions_gender %>% 
  arrange(desc(Mean),by_group = TRUE)

```

### Voters interacted the most with candidates of what race?

```{r}
interactions_race <- df_clean %>%
     group_by(race) %>%
     summarise(n = n(), Engagement = sum(Absolute_Engagement), Mean = mean(Absolute_Engagement), sd = sd(Absolute_Engagement), Comments = sum(Total_Comments), Expenses = mean(Expenses, na.rm = T), ExpensesAds = mean(ExpensesAds, na.rm = TRUE)) 
    

interactions_race %>% 
  arrange(desc(Mean),by_group = TRUE)
```

### Voters interacted the most with candidates of what level of education?

```{r}
interactions_education <- df_clean %>%
     group_by(education) %>%
     summarise(n = n(), Engagement = sum(Absolute_Engagement), Mean = mean(Absolute_Engagement), sd = sd(Absolute_Engagement), Comments = sum(Total_Comments), Expenses = mean(Expenses, na.rm = T), ExpensesAds = mean(ExpensesAds, na.rm = TRUE)) 

interactions_education %>% 
  arrange(desc(Mean),by_group = TRUE)
```

### Intersectional analysis: voters interacted the most with what profile of candidate?

```{r, message=FALSE, warning=FALSE}
#Adding political class
df_clean <- df_clean %>% 
  mutate(PoliticalClass = df_clean$occupation) 
df_clean$PoliticalClass <- case_when(
    df_clean$PoliticalClass %in% c('Deputy', 'Member of City Council') ~ '1', TRUE ~ '0')

# Create the interaction term by combining the categorical variables
df_interaction <- df_clean %>% 
  mutate(interaction = interaction(gender, race, education, sep = " "))

intersectional_analysis <- df_interaction %>%
     group_by(interaction) %>%
     summarise(n = n(), Engagement_Total = sum(Absolute_Engagement), Engagement_Mean = mean(Absolute_Engagement), sd = sd(Absolute_Engagement), Comments = sum(Total_Comments), Expenses = mean(Expenses, na.rm = T), ExpensesAds = mean(ExpensesAds, na.rm = TRUE)) 
    
intersectional_analysis %>% 
  arrange(desc(Engagement_Mean),by_group = TRUE)
```

### Voters interacted the most with candidates of what previous occupation?

```{r}
occupation_interactions <- df_clean %>%
     group_by(occupation) %>%
     summarise(n = n(), Engagement = sum(Absolute_Engagement), Mean = mean(Absolute_Engagement), Expenses = mean(Expenses, na.rm = T), ExpensesAds = mean(ExpensesAds, na.rm = TRUE)) 

occupation_interactions %>% 
  arrange(desc(Mean),by_group = TRUE)
```


### Voters interacted the most with candidates of what political party?

```{r}
interactions_party <- df_clean %>%
     group_by(party_abbrev) %>%
     summarise(n = n(), Engagement = sum(Absolute_Engagement), Mean = mean(Absolute_Engagement), Comments = sum(Total_Comments), Expenses = mean(Expenses, na.rm = T), ExpensesAds = mean(ExpensesAds, na.rm = TRUE))

interactions_party %>% 
  arrange(desc(Mean),by_group = TRUE)
```

### Do these variables explain what candidates received more interactions online?
#### **Z-Transformed Regression Analysis**

Over-dispersal of count data can be verified in our dependent variable if the variance exceeds the means. This is the case with "Relative Engagement".

```{r}
mean(df_clean$Relative_Engagement)
var(df_clean$Relative_Engagement)
```


```{r}
#Transforming the data
df_ztransformed <- df_clean

#Adding political class
df_ztransformed <- df_ztransformed %>% 
  mutate(PoliticalClass = df_ztransformed$occupation) 
df_ztransformed$PoliticalClass <- case_when(
    df_ztransformed$PoliticalClass %in% c('Deputy', 'Member of City Council') ~ '1', TRUE ~ '0')
df_ztransformed$PoliticalClass <- as.factor(df_ztransformed$PoliticalClass)
```

```{r}
#Dealing with missing values
#Removing NAs
df_ztransformed$nr_ads[is.na(df_ztransformed$nr_ads)] <- 0
df_ztransformed$ExpensesAds[is.na(df_ztransformed$ExpensesAds)] <- 0

#Wealth | I want to make sure that the imputation will maintain a similar mean, sd, median and distribution. 
mean(df_ztransformed$Declared_Wealth, na.rm = T)
sd(df_ztransformed$Declared_Wealth, na.rm = T)
median(df_ztransformed$Declared_Wealth, na.rm = T)
```

```{r}
#https://appsilon.com/imputation-in-r/
#install.packages("mice")
library(mice)
df_ztransformed_preliminary <- df_ztransformed %>%
  select(gender, race, education, occupation, PoliticalClass, received_funds, Declared_Wealth)
md.pattern(df_ztransformed_preliminary)
```

```{r}
df_ztransformed_imputed <- data.frame(
  Declared_Wealth = df_ztransformed$Declared_Wealth,
  Wealth_pmm = complete(mice(df_ztransformed_preliminary, method = "pmm"))$Declared_Wealth,
  Wealth_cart = complete(mice(df_ztransformed_preliminary, method = "cart"))$Declared_Wealth)

df_ztransformed_imputed
```

```{r}
#pmm: Predictive mean matching 
mean(df_ztransformed_imputed$Wealth_pmm)
sd(df_ztransformed_imputed$Wealth_pmm)
median(df_ztransformed_imputed$Wealth_pmm)
```

```{r}
#cart: Classification and regression trees
mean(df_ztransformed_imputed$Wealth_cart)
sd(df_ztransformed_imputed$Wealth_cart)
median(df_ztransformed_imputed$Wealth_cart)
```

Result: cart proved to be a better imputation method.

```{r}
df_ztransformed <-cbind(df_ztransformed, df_ztransformed_imputed)
```

```{r}
mean(df_ztransformed$Expenses, na.rm = T)
sd(df_ztransformed$Expenses, na.rm = T)
median(df_ztransformed$Expenses, na.rm = T)
```

```{r}
df_ztransformed_preliminary2 <- df_ztransformed %>%
    select(gender, race, education, PoliticalClass, Wealth_cart, Expenses)
  md.pattern(df_ztransformed_preliminary2)

df_ztransformed_imputed2 <- data.frame(
  Expenses = df_ztransformed$Expenses,
  Expenses_cart = complete(mice(df_ztransformed_preliminary2, method = "cart"))$Expenses)
```

```{r}
mean(df_ztransformed_imputed2$Expenses_cart)
sd(df_ztransformed_imputed2$Expenses_cart)
median(df_ztransformed_imputed2$Expenses_cart)
```

```{r}
df_ztransformed <-cbind(df_ztransformed, df_ztransformed_imputed2)
```

```{r}
#Transforming categorical into interger 
df_ztransformed$gender <- str_replace_all(df_ztransformed$gender,
                                            'Feminine','0')
df_ztransformed$gender <- str_replace_all(df_ztransformed$gender,
                                            'Masculine','1')
df_ztransformed$gender <- as.factor(df_ztransformed$gender)

df_ztransformed$race <- str_replace_all(df_ztransformed$race,
                                          "Non-White", "0")
df_ztransformed$race <- str_replace_all(df_ztransformed$race,
                                          "White", "1")
df_ztransformed$race <- as.factor(df_ztransformed$race)

df_ztransformed$education <- str_replace_all(df_ztransformed$education,
                                            'College incomplete or less','0')
df_ztransformed$education <- str_replace_all(df_ztransformed$education,
                                            'College Complete','1')
df_ztransformed$education <- as.factor(df_ztransformed$education)

#Z Transformation: Subtracting the mean from all values of an observation and dividing the observation by the standard deviation of all values 
df_ztransformed$Expenses_Z <- scale(df_ztransformed$Expenses_cart)
df_ztransformed$ExpensesAds_Z <- scale(df_ztransformed$ExpensesAds)
df_ztransformed$ReceivedFunds_Z <- scale(df_ztransformed$received_funds)
df_ztransformed$Declared_Wealth_Z <- scale(df_ztransformed$Wealth_cart)

# Round the values to integers
df_ztransformed$Relative_Engagement <- round(df_ztransformed$Relative_Engagement)
```

####First iteration

```{r}
# Controling for demographic variables
Model_Z1 <- glm.nb(Relative_Engagement ~ 
                      gender + race + education + Declared_Wealth_Z, 
                 data = df_ztransformed,
                 maxit = 1000)
```

```{r}
# Check for multicollinearity
vif_results_Z1 <- vif(Model_Z1) %>% 
  round(2)
print(vif_results_Z1)
```

```{r}
# Print the summary of the model
summary(Model_Z1)
#tidymodel <- tidy(Model_Z1)
#write.csv2(tidymodel, file = "tidymodel.csv", row.names=FALSE)
```

####Second iteration

```{r}
# Negative binomial regression model
Model_Z2 <- glm.nb(Relative_Engagement ~ 
                      gender + race + education + Declared_Wealth_Z
                    + PoliticalClass + ReceivedFunds_Z + 
                    + ExpensesAds_Z + Expenses_Z, 
                 data = df_ztransformed,
                 maxit = 1000) 
```

```{r}
# Check for multicollinearity
vif_results_Z2 <- vif(Model_Z2) %>% 
  round(2)
print(vif_results_Z2)
```

```{r}
# Print the summary of the model
summary(Model_Z2)
#tidymodel2 <- tidy(Model_Z2)
#write.csv2(tidymodel2, file = "tidymodel2.csv", row.names=FALSE)
```

```{r}
nas_regression <- colSums(is.na(df_ztransformed))
  print(nas_regression)
```

### **Residual diagnosis for the negative binomial test**

```{r}
ResidualsOutput <- simulateResiduals(fittedModel = Model_Z2, plot = F)
#residuals(ResidualsOutput)
plot(ResidualsOutput)
```

**Kolmogorov-Smirnov test: p-value = 0.00046** **\|** The KS test checks if the distribution of the simulated residuals generated by DHARMa significantly differs from the expected distribution under the model. This indicates that the model might not fit the data well in terms of overall distribution.

**Dispersion test: p-value =** 0.792 **\|** The dispersion test assesses if there is a significant deviation in the dispersion of the residuals compared to what the model assumes. A high p-value (0.736) means that there is no significant deviation in the dispersion of residuals. This is a good sign, indicating that the model is doing well in capturing the variability in the data.

**Outlier test: p-value = 0.1 \|** The outlier test checks if there are significant outliers in the data, which can be problematic for the model. A p-value of zero means that there are significant outliers present in the data, and they deviate from what the model expects.

**Summary:** results indicate that the dispersion of the residuals is not significantly deviating from what the model assumes, and the outlier test also had non significant results. However, they indicate that there are significant deviations in terms of the overall distribution (KS test). Additionally, quantile deviations suggest that the model might not be accurately capturing certain patterns in the data at specific points along the distribution.

### Conclusion:
Based on this statistical test, we can conclude that online engagement proved to have a strong relationship with already belonging to Brazil's political class, and an even more significant relationship with campaign and Facebook expenses. These results indicate that Facebook does not level the playing field for candidates, as being an incumbent and having enough economic resources are determinant factors for a candidacy's visibility on that platform.

# [RQ2] Distribution

***What are the constituencies (geographically defined) parliamentarians reached out to the most? Conversely, what constituencies were left aside in this election?***

```{r, echo=T, results='hide', message=FALSE, warning=FALSE}
# All municipalities in the state of Minas Gerais
muni <- read_municipality(code_muni= "MG", 
                          year=2020)

################################
################################
####Transforming Latin/Portuguese characters
## CrowdTangle
CrowdTangle_Clean <- CrowdTangle 
CrowdTangle_Clean$body = stri_trans_general(str = CrowdTangle_Clean$body, id = "Latin-ASCII")                                             #removing accents
CrowdTangle_Clean$body <- tolower(CrowdTangle_Clean$body)  #lower case

##Municipality names
muni_clean <- muni
muni_clean$name_muni = stri_trans_general(str = muni_clean$name_muni, id = "Latin-ASCII")   
muni_clean$name_muni <- tolower(muni_clean$name_muni)

################################
################################
#Tokenization and identification
#First, we need to check whether each element in the body variable contains any of the municipality names.
posts_with_muni <- CrowdTangle_Clean %>% 
          filter(
          str_detect(body, paste(muni_clean$name_muni, collapse = "|"), negate = F)
          )   #The paste() function concatenates the names into a single string, with the collapse argument set to | to create a regular expression pattern that matches any of the names. 
              #The str_detect() function returns a logical vector indicating whether each element in body matches the pattern. The negate = F argument ensures that the matches are not negated (i.e., it returns TRUE for matching elements).
posts_with_muni_clean <- posts_with_muni
posts_with_muni_clean$body = stri_trans_general(str = posts_with_muni_clean$body, id = "Latin-ASCII")   
posts_with_muni_clean$body <- tolower(posts_with_muni_clean$body)

```


```{r, results='hide', message=FALSE, warning=FALSE}
#Identify the occurences in the corpus (both across the dataset and per candidate). 
muni2 <- str_extract_all(
  CrowdTangle_Clean$body, 
  paste(muni_clean$name_muni, collapse = "|"),
  simplify = FALSE)

muni_list <- muni2 %>% 
  unlist() %>%  
  as.data.frame()
  colnames(muni_list) <- "name_muni"  
muni_mentioned <- muni_list %>%  
  group_by(name_muni) %>% 
  count()

#Adding the number of mentions to the datalist 
muni_clean <- as.data.frame(muni_clean) 
muni3 <- left_join(muni_clean, muni_mentioned, by = "name_muni", copy = FALSE, keep = FALSE)

muni3$freq <- muni3$freq %>% replace_na(0)

####################################################
####################################################
########  REPLACE AMBIGUOUS NAMES (SEE ADITIONAL FOLDER) 
muni3 <- muni3 %>%
  mutate(n = ifelse(name_muni == "bandeira", 28, n))  %>% 
  mutate(n = ifelse(name_muni == "conquista", 12, n)) %>% 
  mutate(n = ifelse(name_muni == "divino", 65, n))    %>% 
  mutate(n = ifelse(name_muni == "extrema", 22, n))   %>%
  mutate(n = ifelse(name_muni == "liberdade", 9, n))  %>%
  mutate(n = ifelse(name_muni == "luz", 5, n))        %>% 
  mutate(n = ifelse(name_muni == "machado", 43, n))   %>% 
  mutate(n = ifelse(name_muni == "passos", 103, n))   %>% 
  mutate(n = ifelse(name_muni == "paiva", 1, n))      %>% 
  mutate(n = ifelse(name_muni == "campanha", 4, n))   %>% 
  mutate(n = ifelse(name_muni == "cristina", 0, n))   %>% 
  mutate(n = ifelse(name_muni == "goncalves", 0, n))  %>% 
  mutate(n = ifelse(name_muni == "pimenta", 15, n))
```

```{r, results='hide', message=FALSE, warning=FALSE}
#UNIQUE MENTIONS PER CANDIDATE
#Exclude ambiguous names 
ambiguous_names <- c("campanha", "cristina", "bandeira", "conquista", "divino", "extrema", "goncalves", "liberdade", "luz", "machado", "passos", "paiva", "pimenta")
filtered_muni_names <- muni_clean$name_muni[!(muni_clean$name_muni %in% ambiguous_names)]

###############################
# Count mentions of filtered_muni_names in the body column
muni_mentions_analysis <-  posts_with_muni %>%
  mutate(mentioned_cities = str_extract_all(body, paste(filtered_muni_names, collapse = "|"))) %>%
  unnest(mentioned_cities) %>%
  group_by(page_name, mentioned_cities) %>%
  summarise(
    total_mentions = n(),
    unique_mentions = 1,
    cities_mentioned = paste(mentioned_cities, collapse = ", ")
  ) %>%
  group_by(page_name) %>%
  summarise(
    total_mentions = sum(total_mentions),        #Total count of city mentions for each candidate
    unique_mentions = n(),                       #Number of unique cities mentioned for each candidate
    cities_mentioned = list(unique(mentioned_cities))   #A list of city names mentioned by each candidate
  )

###############################
#### Adding ambiguous names ###
###############################
muni_mentions_analysis_combined <- full_join(muni_mentions_analysis, muni_ambiguous_analysis, by = c("page_name" = "page_name.y")) %>%
  mutate(
    total_mentions = ifelse(is.na(total_mentions.y), total_mentions, total_mentions + total_mentions.y),
    unique_mentions = ifelse(is.na(unique_mentions.y), unique_mentions, unique_mentions + unique_mentions.y),
    cities_mentioned = map2(cities_mentioned, cities_mentioned.y, union)
  ) %>%
  select(page_name, total_mentions, unique_mentions, cities_mentioned)
```

**What is the average number of unique city mentions by a candidate?**

```{r}
mean(muni_mentions_analysis_combined$unique_mentions, na.rm = TRUE)
median(muni_mentions_analysis_combined$unique_mentions, na.rm = TRUE)
sd(muni_mentions_analysis_combined$unique_mentions, na.rm = TRUE)
```

**What is the average number of city mentions by a candidate?**

```{r}
mean(muni_mentions_analysis_combined$total_mentions, na.rm = TRUE)
median(muni_mentions_analysis_combined$total_mentions, na.rm = TRUE)
sd(muni_mentions_analysis_combined$total_mentions, na.rm = TRUE)
```

**Adding Census Data**

```{r}
MGMunicipalities_Clean <- MGMunicipalities
MGMunicipalities_Clean$name_muni = stri_trans_general(str = MGMunicipalities_Clean$name_muni, id = "Latin-ASCII")   #removing accents
MGMunicipalities_Clean$name_muni <- tolower(MGMunicipalities_Clean$name_muni) #lower case

IBGE <- left_join(muni3, MGMunicipalities_Clean, by = "name_muni", copy = T, keep = FALSE)
IBGE <- replace(IBGE, is.na(IBGE), 0)
```

**How many municipalities were mentioned less than ten times?**

```{r}
sum(IBGE$n <10, na.rm=TRUE)
```

# Correlations

```{r}
CorrelationPopulation <- cor.test(IBGE$n, IBGE$Population, 
                    method = "pearson")
#Correlation between mentions and Human Development Index (IDHM, in Portuguese)
CorrelationGINI <- cor.test(IBGE$n, IBGE$GINI,method = "pearson")
CorrelationPIB <- cor.test(IBGE$n, IBGE$PIB_per_capita, method = "pearson")


CorrelationPopulation
CorrelationGINI
CorrelationPIB
```

```{r}
ggplot(data = IBGE) + 
  geom_jitter() +
  aes(x = n, y = GINI, color = Mesoregion)+
  labs(title = "Relationship between mentions and Human Development Index", x = "Mentions", y = "Human Development Index")
```

```{r}
ggplot(data = IBGE) + 
  geom_jitter() +
  aes(x = n, y = Population, color = Mesoregion)+
  labs(title = "Relationship between mentions and population", x = "Mentions", y = "Population")
```

```{r}
ggplot(data = IBGE) + 
  geom_jitter() +
  aes(x = n, y = PIB_per_capita, color = Mesoregion)+
  labs(title = "Relationship between mentions and PIB", x = "Mentions", y = "PIB per capita")
```

```{r, message=FALSE, warning=FALSE}
BV <- ggplot()+
  geom_jitter(data=IBGE, aes(x = n, y = Population, text=name_muni)) + 
  labs(title = "Relationship between mentions and population (estimated for 2021)", x = "Mentions", y = "population")+
  guides(fill = guide_colourbar(title = "Mentions")) 
  
InteractivePopulation <- ggplotly(BV)
InteractivePopulation
```

```{r}
BV + facet_wrap(vars(Mesoregion))
```

```{r}
ggplot(data = IBGE) + 
  geom_jitter() +
  aes(x = n, y = PIB_per_capita, color = Mesoregion)+
  labs(title = "Relationship between PIB per capita and mentions", x = "Mentions", y = "PIB per capita")
```

## **Regression**

```{r}
hist(IBGE$Medium_Salary, 
     breaks = 100,  # Choose the number of bins automatically using the 'FD' method
     col = "skyblue",  # Set the color of the bars
     border = "white",  # Set the color of the bar borders
     ylab = "",
     xlab = "",  # Set the x-axis label
     main = "Histogram of Population"  # Set the main title
)
```

```{r}
IBGE_log <- IBGE

#Log transformation
IBGE_log$Population <- log(IBGE_log$Population + 1)
IBGE_log$PIB_per_capita <- log(IBGE_log$PIB_per_capita + 1)
IBGE_log$Urban_Area <- log(IBGE_log$Urban_Area + 1)
IBGE_log$Demographic_Density <- log(IBGE_log$Demographic_Density + 1)


hist(IBGE_log$Population, 
     col = "skyblue",  # Set the color of the bars
     border = "white",  # Set the color of the bar borders
     xlab = "",  # Set the x-axis label
     main = "Histogram of Population"  # Set the main title
)

```

```{r}
Model_Geo <- lm(n ~ Population + GINI + Medium_Salary 
                       + Urban_Area + Demographic_Density,
                       data = IBGE_log)
```

```{r}
omnibus_geo <- Anova(Model_Geo, type = "III")
omnibus_geo
```

```{r}
# Check for multicollinearity 
vif_geo <- vif(Model_Geo)
print(vif_geo)
```

```{r}
summary(Model_Geo)
#To export the results, use tidy and then create a data frame 
tidymodel_geo <- tidy(Model_Geo)
```

## Geographical analysis

Based on the number of times municipalities *mineiras* were mentioned, I plotted an interactive choropleth map. The map allows the reader to hoover over the municipalities and see their names and the number of times they were mentioned.

```{r, message=FALSE, warning=FALSE}
# Ploting an interactive choropleth map
Map <- ggplot() +
  geom_sf(data=IBGE, aes(fill=n, text = paste(name_muni, "population:", Population), geometry = geom), color= NA, size=.15) + 
    labs(title="2022 Election: municipalities mentioned", size=10) +
    guides(fill = guide_colourbar(title = "Mentions")) +
    theme_minimal() +
    theme(axis.line = element_blank(), axis.text = element_blank(),
        axis.ticks = element_blank(), axis.title = element_blank(),
        panel.grid = element_blank()) +
    scale_fill_viridis(limits = c(0, 2200))

InteractiveMap <- ggplotly(Map) %>% 
  layout(title = list(text = paste0("<B>2022 Election: municipalities mentioned</B>")))

InteractiveMap
```