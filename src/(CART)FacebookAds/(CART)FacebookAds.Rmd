---
title: "CartographiesFBADS"
author: "André K. Rodarte"
date: "2023-08-22"
output: html_document
---

```{r setup, include=FALSE}
### References ####
#RadLibrary: https://github.com/facebookresearch/Radlibrary
#devtools::install_github("facebookresearch/Radlibrary")
#remotes::install_github("favstats/metatargetr")

library(readr)
library(tidyverse)
library(tidytext)
library(dplyr)
library(janitor)
library(highcharter)
library(httr)
library(furrr)
library(remotes)
library(lubridate)
library(purrr)
library(data.table)
library(stringdist)
library(stringi)

#DATA VISUALIZATION
#install.packages('maps')
#install.packages("tibble")
#install.packages("forcats")
#install.packages("plotly")
#install.packages("sf")
library(ggplot2)
library(plotly)
library(sf)
library(maps)
library(tibble)
library(forcats)

#Regression analysis
#install.packages("caret")
#install.packages("car")
#install.packages("leaps")
#install.packages("MASS")
#install.packages("partykit")
#install.packages("nnet")
#install.packages("EMT")
library(caret)
library(car)
library(leaps)
library(MASS)
library(partykit)
library(nnet)
library(EMT)

#################################
###########FUNCTIONS#############
#################################
get_mid <- function(spend_upper_bound, spend_lower_bound) {
  # (spend_upper_bound-spend_lower_bound)/2+spend_lower_bound
  (spend_upper_bound+spend_lower_bound)/2
}

# Data on the municipalities of the state of Minas Gerais (MG)
# MGMunicipalities <- read_csv("data/ListMunicipalitiesIBGE.csv",
#   col_types = cols(
#     Population = col_number(),
#     Medium_Salary = col_number(), 
#     PIB_per_capita = col_number(),
#     GINI = col_number(), 
#     Area = col_number(),
#     Urban_Area = col_number(), 
#     Demographic_Density = col_number()
#   )
# )
# MGMunicipalities_Clean <- MGMunicipalities
# MGMunicipalities_Clean$name_muni <- stri_trans_general(str = MGMunicipalities_Clean$name_muni, id = "Latin-ASCII") # removing accents
# MGMunicipalities_Clean$name_muni <- tolower(MGMunicipalities_Clean$name_muni) # lower case

```

# Facebook Ads Query 
You will need to set up API Credentials for the following procedure

```{r setup, include=FALSE}
# Set up API credentials
access_token <- "E" #add here your own credentials

# Define the API endpoint URL
api_base_url <- "https://graph.facebook.com"
api_version <- "v15.0"  # Replace if necessary
endpoint <- file.path(api_base_url, api_version, "ads_archive")
```

#Query
Our query procedure consisted of using four keywords (“vote,” “Minas Gerais,” “deputado federal,” “eleições”) and setting the ad delivery region to Minas Gerais. This process yielded 30,657 ads. We then removed those not created by candidates in our sample, resulting in a final corpus of 9,431 ads from 228 accounts. 

```{r}
# First, save all of the data types that we will ask the API to extract.
fields_vector <- c("ad_data", "region_data", "demographic_data")

# Correspondingly, save all of the table types.
table_type_vector <- c("ad", "region", "demographic")

# Initiate an empty list to which we will append the extracted API data.
# The list could be initiated simply by using list(); however, especially for
# larger data sets, specifying the length of a list in R in advance speeds up
# the processing. The length of the list equals our 3 data types.
fb_ad_list <- vector(mode = "list", length = length(fields_vector))

# We will also name its three items with values from table_type_vector so we can
# refer to them further
names(fb_ad_list) <- table_type_vector

for (i in seq_along(fields_vector)) {
  print(paste("Extracting the", fields_vector[i]))
  
  query3 <- adlib_build_query(
    ad_reached_countries = "BR",
    ad_active_status = "ALL",
    search_terms = "Minas Gerais", #We used four keywords (“vote,” “Minas Gerais,” “deputado federal,” “eleições”)
    #search_page_ids =
    ad_delivery_date_min = "2022-01-01",
    ad_delivery_date_max = "2022-10-02",
    ad_type = "POLITICAL_AND_ISSUE_ADS",
    publisher_platform = c(
      "FACEBOOK",
      "INSTAGRAM",
      "MESSENGER",
      "WHATSAPP"
    ),
    fields = fields_vector[i]
  )
  
  # The call is limited to 1000 results but pagination of overcomes it.
  # We pipe the output of the paginated call to the as_tibble function.
  fb_ad_list[[table_type_vector[i]]] <- adlib_get_paginated(query3,
                                                            token = access_token
  ) %>%
    as_tibble(
      type = table_type_vector[i],
      censor_access_token = TRUE
    )
}
```

### Summary of Ads 

```{r, warning=FALSE}
#Write dataset
df_terms <- fb_ad_list[["ad"]] %>%
  distinct() %>%
  arrange(desc(ad_creation_time))
#Our first dataset contains 31,098 ads. This dataset was uploaded to the folder "data".
    # df_terms <- read_csv(
    #   "../data/df_terms.csv"
    # )

#Combine by name
df_ads <- df_terms %>%
  group_by(page_name) %>%
  summarise(
    id = first(id),
    nr_ads = n(),
    spend_upper_sum = sum(spend_upper, na.rm = TRUE),
    spend_lower_sum = sum(spend_lower, na.rm = TRUE),
    impressions_upper_avg = mean(impressions_upper, na.rm = TRUE),
    #avg_prop_female_25_34 = mean(`female_25-34`, na.rm = TRUE),
    #avg_prop_male_25_34 = mean(`male_25-34`, na.rm = TRUE),
  ) %>%
  filter(nr_ads > 1) %>%
  arrange(desc(nr_ads)) %>% 
  mutate(mid_spent = get_mid(spend_upper_sum, spend_lower_sum))

head(df_ads, 20)
```

 
**Accounts that promoted ads but could not be found in Crowdtangle**
Next, we compared our ads dataset (df_ads) with the dataset we had created with organic posts (see "Cartografia2022Election.Rmd" to obtain the latter)

```{r}
## Standardize the case (converting to lowercase)
## Remove leading and trailing white spaces
df$page_name <- trimws(df$page_name)
df$name_ballot <- trimws(df$name_ballot)
df$page_name <- tolower(df$page_name)
df$name_ballot <- tolower(df$name_ballot)

df_ads$page_name <- trimws(df_ads$page_name)
df_ads$page_name <- tolower(df_ads$page_name)

df$page_name = stri_trans_general(str = df$page_name, id = "Latin-ASCII")
df_ads$page_name = stri_trans_general(str = df_ads$page_name, id = "Latin-ASCII")

# Define a threshold for Levenshtein distance to consider as a match
threshold <- 0.1

# Find approximate matches between "page_name" and "name_ballot" and store similarity information
similarity_info <- data.frame()
for (i in 1:nrow(df_ads)) {
  page_name <- df_ads$page_name[i]
  matches <- stringdist::amatch(page_name, df$name_ballot, method = "lv")
  filtered_matches <- matches[stringdist::stringdistmatrix(page_name, df$name_ballot[matches], method = "lv") <= threshold]
  
  if (length(filtered_matches) > 0) {
    match_info <- data.frame(page_name = page_name, name_ballot = df$name_ballot[filtered_matches], similarity = threshold - stringdist::stringdist(page_name, df$name_ballot[filtered_matches], method = "lv"))
    similarity_info <- rbind(similarity_info, match_info)
  }
}

# Print the resulting dataset with similarity information
df_similarity <- na.omit(similarity_info)

#Check for different accounts
differences_df <- setdiff(df_similarity$page_name, df$page_name)
differences_df <- data.frame(page_name = differences_df, Indicator = "Only in df")
 
```

This analysis revealed 56 accounts that paid for FB ads but Crowdtangle could not identify them. These accounts can be found in df_differences_df_clean.

#### Combine original df with data about FB ads.

```{r}
# #Merge datasets 
df_ads_combined <- left_join(df, df_ads, by = "page_name", na_matches = "never")
```

Now, we will remove from df_terms all posts that were not created by our sample.

```{r}
df_terms_clean <- df_terms %>% 
  select_if(~ !is.list(.))

df_terms_clean$ad_creative_bodies = stri_trans_general(str = df_terms_clean$ad_creative_bodies, id = "Latin-ASCII") #removing accents
df_terms_clean$ad_creative_bodies <- tolower(df_terms_clean$ad_creative_bodies)  #lower case
df_terms_clean$page_name <- tolower(df_terms_clean$page_name)
df_terms_clean$page_name <- trimws(df_terms_clean$page_name)
df_terms_clean$page_name = stri_trans_general(str = df_terms_clean$page_name, id = "Latin-ASCII")
# write.csv(df_terms_clean, "df_terms_clean.csv", row.names = FALSE)

################################
#Tokenization and identification

#First, we will remove all ads that were not created by our sample:
page_names_list <- unique(df_ads_combined$page_name)
df_terms_filtered <- df_terms_clean %>%
  filter(page_name %in% page_names_list)

accounts_with_ads <- length(unique(df_terms_filtered$page_name))
accountsID_with_ads <- length(unique(df_terms_filtered$page_id))

#Second, we need to check whether each element in the body variable contains any of the municipality names.
ads_with_muni <- df_terms_filtered %>% 
          filter(
          str_detect(ad_creative_bodies, paste(muni_clean$name_muni, collapse = "|"), negate = F)
          )   
# write.csv(df_terms_filtered, "df_terms_filtered.csv", row.names = FALSE)
```
Percentage of candidates who ran adds (considering that there were 1,018 candidates in total)
```{r}
total_accounts <- 1018
percentage_with_ads <- (accountsID_with_ads / total_accounts) * 100
```

*Summary of results*: 
We identified 9,431 ads created by 248 accounts in our sample (of which 228 had a unique name), which correspond to 24.37% of our sample. 

4,245 out of these ads contained references to Minas Gerais municipalities.

Next, we need to prepare the data for our analysis
```{r}
ads <- str_extract_all(
  df_terms_filtered$ad_creative_bodies, 
  paste(muni_clean$name_muni, collapse = "|"), 
  simplify = FALSE)

ads_list <- ads %>% 
  unlist() %>%  
  as.data.frame()
  colnames(ads_list) <- "name_muni"  
ads_muni_mentioned <- ads_list %>%  
  group_by(name_muni) %>% 
  count()

#Adding the number of mentions to the datalist 
muni4 <- left_join(muni_clean, ads_muni_mentioned, by = "name_muni", copy = FALSE, keep = FALSE)
muni4$n <- muni4$n %>% replace_na(0)

```

### Replace ambiguous names
We conducted a UPD + manual analysis of  all posts containing ambiguous municipality names, so that we could make sure whether a candidate was referring to one of them. The specific posts which did so can be found in "Manual ambiguous ads identification.txt". More information can be found in "AmbiguousAds.Rmd"
```{r}
muni4 <- muni4 %>%
  mutate(n = ifelse(name_muni == "bandeira", 8, n))  %>% 
  mutate(n = ifelse(name_muni == "conquista", 0, n)) %>% 
  mutate(n = ifelse(name_muni == "divino", 2, n))    %>% 
  mutate(n = ifelse(name_muni == "extrema", 12, n))   %>%
  mutate(n = ifelse(name_muni == "liberdade", 0, n))  %>%
  mutate(n = ifelse(name_muni == "luz", 0, n))        %>% 
  mutate(n = ifelse(name_muni == "machado", 40, n))   %>% 
  mutate(n = ifelse(name_muni == "passos", 40, n))   %>% 
  mutate(n = ifelse(name_muni == "paiva", 3, n))      %>% 
  mutate(n = ifelse(name_muni == "campanha", 0, n))   %>% 
  mutate(n = ifelse(name_muni == "cristina", 1, n))   %>% 
  mutate(n = ifelse(name_muni == "goncalves", 6, n))  %>% 
  mutate(n = ifelse(name_muni == "pimenta", 1, n))
```

### Determining the number of unique mentions per candidate

```{r, results='hide', message=FALSE, warning=FALSE}
#Exclude ambiguous names 
ambiguous_names <- c("campanha", "cristina", "bandeira", "conquista", "divino", "extrema", "goncalves", "liberdade", "luz", "machado", "passos", "paiva", "pimenta")
filtered_muni_names <- muni_clean$name_muni[!(muni_clean$name_muni %in% ambiguous_names)]

###############################
###############################
# Count mentions of filtered_muni_names in the body column
muni_mentions_analysis_ads <-  ads_with_muni %>%
  mutate(mentioned_cities = str_extract_all(ad_creative_bodies, paste(filtered_muni_names, collapse = "|"))) %>%
  unnest(mentioned_cities) %>%
  group_by(page_name, mentioned_cities) %>%
  summarise(
    total_mentions = n(),
    unique_mentions = 1,
    cities_mentioned = paste(mentioned_cities, collapse = ", ")
  ) %>%
  group_by(page_name) %>%
  summarise(
    total_mentions = sum(total_mentions), #Total count of city mentions for each candidate
    unique_mentions = n(),  #Number of unique cities mentioned for each candidate
    cities_mentioned = list(unique(mentioned_cities))   #A list of city names mentioned by each candidate
  )

###############################
#### Adding ambiguous names ###
###############################
#For the following procedure, we uploaded the dataset "df_ambiguous_ads" from our data folder. This dataset was created based on our UPD and qualitative reading procedures, which can be found in "AmbiguousAds.Rmd". 

# First, we count the mentions of ambiguous names in the ads.
muni_ambiguous_analysis_ads <-  df_ambiguous_ads %>%
  mutate(mentioned_cities = str_extract_all(ad_creative_bodies.y, paste(ambiguous_names, collapse = "|"))) %>%
  unnest(mentioned_cities) %>%
  group_by(page_name.y, mentioned_cities) %>%
  summarise(
    total_mentions = n(),
    unique_mentions = 1,
    cities_mentioned = paste(mentioned_cities, collapse = ", ")
  ) %>%
  group_by(page_name.y) %>%
  summarise(
    total_mentions.y = sum(total_mentions),#Total count of city mentions for each account
    unique_mentions.y = n(),#Number of unique cities mentioned for each page_name.
    cities_mentioned.y = list(unique(mentioned_cities))#A list of city names mentioned by each account
  )

#Next, we combine both datasets
muni_mentions_analysis_ads_combined <- full_join(muni_mentions_analysis_ads, muni_ambiguous_analysis_ads, by = c("page_name" = "page_name.y")) %>%
  mutate(
    total_mentions = ifelse(is.na(total_mentions.y), total_mentions, total_mentions + total_mentions.y),
    unique_mentions = ifelse(is.na(unique_mentions.y), unique_mentions, unique_mentions + unique_mentions.y),
    cities_mentioned = map2(cities_mentioned, cities_mentioned.y, union)
  ) %>%
  select(page_name, total_mentions, unique_mentions, cities_mentioned)
```

# **RQ: Do congressional candidates target municipalities in a way that is consistent with their claims to scatter in the corners of the nation?**

## **What is the average number of unique city mentions by a candidate?**

```{r}
mean(muni_mentions_analysis_ads_combined$unique_mentions, na.rm = TRUE)
median(muni_mentions_analysis_ads_combined$unique_mentions, na.rm = TRUE)
sd(muni_mentions_analysis_ads_combined$unique_mentions, na.rm = TRUE)
```
**What is the average number of city mentions by a candidate?**

```{r}
mean(muni_mentions_analysis_ads_combined$total_mentions, na.rm = TRUE)
median(muni_mentions_analysis_ads_combined$total_mentions, na.rm = TRUE)
sd(muni_mentions_analysis_ads_combined$total_mentions, na.rm = TRUE)
```
**Adding Census Data**
```{r}
IBGE_ads <- left_join(muni4, MGMunicipalities_Clean, by = "name_muni", copy = T, keep = FALSE)
IBGE_ads <- replace(IBGE_ads, is.na(IBGE_ads), 0)
```

**How many municipalities were mentioned less than ten times?**
```{r}
sum(IBGE_ads$n <10, na.rm=TRUE)
```
### Correlations
```{r}
CorrelationIDHM_ads <- cor.test(IBGE_ads$n, IBGE_ads$GINI, 
                    method = "pearson")
CorrelationPopulation_ads <- cor.test(IBGE_ads$n, IBGE_ads$Population, 
                    method = "pearson")
CorrelationPIB_ads <- cor.test(IBGE_ads$n, IBGE_ads$PIB_per_capita, 
                           method = "pearson")
CorrelationPopulation_ads
CorrelationIDHM_ads
CorrelationPIB_ads
```

```{r}
hist(IBGE_ads$n, 
     breaks = 100,  
     col = "skyblue",
     border = "white",  
     ylab = "",
     xlab = "",
     main = "Histogram of Mentions"  
)
```
**Adding local candidacies**
```{r}
#Candidates' municipalities of origin
df_ads_combined$NM_MUNICIPIO_NASCIMENTO = stri_trans_general(str = df_ads_combined$NM_MUNICIPIO_NASCIMENTO, id = "Latin-ASCII")
df_ads_combined$NM_MUNICIPIO_NASCIMENTO <- tolower(df_ads_combined$NM_MUNICIPIO_NASCIMENTO)
```

```{r}
#Creating a binary variable indicating whether the candidate was born in that municipality
IBGE_ads$Candidate_Born <- ifelse(IBGE_ads$name_muni %in% df_ads_combined$NM_MUNICIPIO_NASCIMENTO, 1, 0)
```

## **Coefficients For Linear Regression Model Examining Relationships Between Municipalities’ Characteristics (Log Transformed) And The Number Of Times They Were Mentioned In Facebook Ads.**
These are the regression models used for Table A2

```{r}
IBGE_ads_log <- IBGE_ads
IBGE_ads_log <- IBGE_ads_log %>%
  rename(Ads_Count = n)

#Log transformations 
IBGE_ads_log$Ads_Count <- log(IBGE_ads_log$Ads_Count + 1)
IBGE_ads_log$Population <- log(IBGE_ads_log$Population + 1)
IBGE_ads_log$Medium_Salary <- log(IBGE_ads_log$Medium_Salary +1)
IBGE_ads_log$Demographic_Density <- log(IBGE_ads_log$Demographic_Density + 1)

# hist(IBGE_ads_log$Ads_Count, 
#      col = "skyblue",
#      border = "white",
#      xlab = "",  
#      main = "Histogram of Mentions"  
# )
```

```{r}
Model_ads_Geo <- lm(Ads_Count ~ Population + GINI + Medium_Salary + Demographic_Density + as.factor(Candidate_Born),
                       data = IBGE_ads_log) 
```

```{r}
omnibus_ads_geo <- Anova(Model_ads_Geo, type = "III")
omnibus_ads_geo
```

```{r}
# Check for multicollinearity using vif()
vif_ads_geo <- vif(Model_ads_Geo)
print(vif_ads_geo)
```
```{r}
summary(Model_ads_Geo)
tidymodel_geo_ads <- tidy(Model_ads_Geo) %>%
  as_tibble() %>%  
  mutate(across(where(is.numeric), ~ round(., 2)))
```
*Summary of results*
Our regression analysis tested whether which predictors were associated with mentions in social media ads (Table A2 in the Appendix), revealing that population (β = 0.44, p<0.001) and inequality (β = 2.82, p<0.001) were significantly related to our dependent variable.


## Geographical visual analysis
Based on the number of times municipalities *mineiras* were mentioned in ads, we plotted an interactive choropleth map. The map allows the reader to hoover over the municipalities and see their names and the number of times they were mentioned.

```{r}
# Black and white color scale
custom_colors <- colorRampPalette(c("#D3D3D3", "black"))(n = 100)

# Choropleth map
Map_ads_black <- ggplot(data=IBGE_ads) +
  geom_sf(aes(fill=n, text=Name, geometry=geom), color= NA, size=.15) + 
    labs(title="2022 Election: municipalities mentioned", size=10) +
  guides(fill = guide_colourbar(title = "Mentions")) +
  theme_minimal() +
  theme(
    axis.line = element_blank(), axis.text = element_blank(),
    axis.ticks = element_blank(), axis.title = element_blank(),
    panel.grid = element_blank()
  ) +
  scale_fill_gradientn(
    colours = custom_colors
  )

InteractiveAdsMapBlack <- ggplotly(Map_ads_black) %>%
  layout(title = list(text = paste0("<B>2022 Election: municipalities mentioned</B>")))

InteractiveAdsMapBlack
```